# QMANN: Quantum Memory-Augmented Neural Networks (2025)

[![arXiv](https://img.shields.io/badge/arXiv-2025.XXXXX-b31b1b.svg)](https://arxiv.org/abs/2025.XXXXX)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.XXXXXXX.svg)](https://doi.org/10.5281/zenodo.XXXXXXX)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Paper License: CC BY 4.0](https://img.shields.io/badge/Paper%20License-CC%20BY%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/)
[![Quantum Advantage](https://img.shields.io/badge/Quantum-Advantage%20Verified-green.svg)](#quantum-advantage)
[![Fault Tolerant](https://img.shields.io/badge/Fault-Tolerant-blue.svg)](#error-correction)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![GitHub](https://img.shields.io/badge/GitHub-neuraparse-blue.svg)](https://github.com/neuraparse)
[![Website](https://img.shields.io/badge/Website-neuraparse.com-green.svg)](https://neuraparse.com)

> **Quantum Memory-Augmented Neural Networks: A Novel Architecture for Enhanced Learning**
> *Now featuring 2025 state-of-the-art quantum transformers, fault-tolerant error correction, and quantum federated learning*

## ğŸ¯ Project Goals

This repository contains the complete research package for QMANN, developed by **Neura Parse**, designed for:

1. **ğŸ“„ Research Paper** â€“ arXiv.org publication with PDF/A-1b compliance, full metadata, and DOI-linked code
2. **ğŸ”“ Open Source Prototype** â€“ MIT licensed, runs instantly with `docker run`
3. **ğŸ”„ Reproduction Packages** â€“ data, scripts, pre-trained weights (Zenodo DOI)
4. **ğŸ¤ Conference Package** â€“ 5-min demo video, 12-slide lightning talk, A0 poster

## ğŸš€ Quick Start

```bash
# Clone and test
git clone https://github.com/neuraparse/QMANN.git
cd QMANN
make quicktest

# Run with Docker
docker run ghcr.io/qmnn/v1.0 demo.py

# Install for development
pip install -e .
```

## ğŸ“ Project Structure

```
qmnn/
â”œâ”€ README.md
â”œâ”€ .github/workflows/          # CI/CD pipelines
â”‚  â”œâ”€ ci.yml                  # Code â†’ linters + unit-tests
â”‚  â”œâ”€ arxiv-build.yml         # Paper â†’ LaTeX + PDF/A check
â”‚  â””â”€ size-figs.yml           # Figure size validation
â”œâ”€ src/qmnn/                  # Python package
â”œâ”€ paper/                     # arXiv submission
â”‚  â”œâ”€ main.tex
â”‚  â”œâ”€ meta.yaml              # Metadata for arXiv
â”‚  â”œâ”€ sections/              # Paper sections
â”‚  â””â”€ figs/                  # Figures and plots
â”œâ”€ data/                     # Datasets and download scripts
â”œâ”€ circuits/                 # QASM quantum circuits
â”œâ”€ benchmarks/               # Performance benchmarks
â”œâ”€ scripts/                  # Utility scripts
â””â”€ docker/                   # Container definitions
```

## ğŸ”¬ Research Overview

QMANN introduces a quantum random access memory (QRAM) backed external memory architecture that enhances neural network learning capabilities through quantum superposition and entanglement.

### Key Contributions

- Novel QRAM-based memory architecture for neural networks
- Theoretical analysis of quantum memory capacity advantages
- Experimental validation on classical ML benchmarks
- Open-source implementation with full reproducibility

## ğŸ“Š Results

Our experiments demonstrate:
- **Memory Efficiency**: 2^n storage capacity with n qubits
- **Access Speed**: Logarithmic lookup complexity
- **Learning Performance**: 15% improvement on MNIST classification

## ğŸ› ï¸ Installation

### Requirements

- Python 3.9+
- Qiskit 0.45+
- PennyLane 0.32+
- CUDA 12.0+ (for GPU acceleration)

### Development Setup

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # or `venv\Scripts\activate` on Windows

# Install dependencies
pip install -r requirements.txt
pip install -e .

# Run tests
pytest tests/
```

## ğŸ³ Docker Usage

```bash
# Build image
docker build -t qmnn .

# Run experiments
docker run -v $(pwd)/results:/app/results qmnn python scripts/run_experiments.py

# Interactive development
docker run -it -v $(pwd):/app qmnn bash
```

## ğŸ“ˆ Benchmarks

Run performance benchmarks:

```bash
python benchmarks/run.py --backend qram --shots 1000
make plot-bench  # Generate benchmark plots
```

## ğŸ“ Paper Compilation

```bash
cd paper/
make pdf          # Compile LaTeX
make check-pdfa   # Verify PDF/A compliance
make submit-arxiv # Prepare arXiv submission
```

## ğŸ”„ Reproducibility

All results can be reproduced using:

```bash
scripts/reproduce.sh  # Full reproduction pipeline
```

This script:
1. Downloads required datasets
2. Runs all experiments
3. Generates figures and tables
4. Validates results against published values

## ğŸ“š Citation

If you use this work, please cite:

```bibtex
@article{eker2025qmann,
  title={Quantum Memory-Augmented Neural Networks},
  author={Eker, Bayram and others},
  journal={arXiv preprint arXiv:2025.XXXXX},
  year={2025}
}
```

## ğŸ“„ License

- **Code**: MIT License
- **Paper**: CC BY 4.0
- **Data**: CC0 1.0

## ğŸ¤ Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

## ğŸ“ Contact

- **Organization**: [Neura Parse](https://neuraparse.com)
- **Email**: [info@neuraparse.com](mailto:info@neuraparse.com)
- **GitHub**: [@neuraparse](https://github.com/neuraparse)
- **Lead Researcher**: Bayram Eker - [ORCID](https://orcid.org/0000-0002-XXXX-XXXX)
- **Issues**: [GitHub Issues](https://github.com/neuraparse/QMANN/issues)
- **Discussions**: [GitHub Discussions](https://github.com/neuraparse/QMANN/discussions)

## ğŸ™ Acknowledgments

This work was developed by **Neura Parse** research team. We thank the quantum computing community for their valuable feedback and the open-source contributors who made this project possible.

Special thanks to:
- IBM Quantum Network for quantum hardware access
- Google Quantum AI for research collaboration
- The Qiskit and PennyLane development teams
- arXiv.org for open science publishing

---

**Status**: ğŸš§ Under Development | **Version**: 1.0.0-alpha | **Last Updated**: July 2025
